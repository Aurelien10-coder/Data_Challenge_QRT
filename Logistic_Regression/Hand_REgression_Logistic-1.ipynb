{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_home=pd.read_csv('/Users/aurelientarroux/Desktop/Projet_prog/Projet_1/Data/Train_Data/train_home_team_statistics_df.csv')\n",
    "df_away=pd.read_csv('/Users/aurelientarroux/Desktop/Projet_prog/Projet_1/Data/Train_Data/train_away_team_statistics_df.csv')\n",
    "\n",
    "df_home.columns='home_'+df_home.columns\n",
    "df_away.columns='away_'+df_away.columns\n",
    "\n",
    "df_result=pd.read_csv('/Users/aurelientarroux/Desktop/Projet_prog/Projet_1/Data/Y_train_1rknArQ.csv')\n",
    "\n",
    "base_match=pd.merge(df_home,df_away,left_on=\"home_ID\",right_on='away_ID',how='inner')\n",
    "base=pd.merge(base_match,df_result,left_on=\"home_ID\",right_on='ID',how='inner')\n",
    "base=base.drop(['home_ID','home_LEAGUE','home_TEAM_NAME','away_ID','away_LEAGUE','away_TEAM_NAME'],axis=1)\n",
    "\n",
    "def resultat(row):\n",
    "    if row['HOME_WINS']==1:\n",
    "        return 'HOME'\n",
    "    elif row['AWAY_WINS']==1:\n",
    "        return 'AWAY'\n",
    "    else:\n",
    "        return 'DRAW'\n",
    "\n",
    "base['Resultat']=base.apply(resultat, axis=1)\n",
    "base=base.drop(['HOME_WINS','AWAY_WINS','DRAW'],axis=1)\n",
    "\n",
    "base.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X = base.drop(['Resultat','ID'],axis=1)\n",
    "y = base['Resultat']\n",
    "\n",
    "encoded_y = pd.get_dummies(y).applymap(lambda x: 1 if x else 0)\n",
    "encoded_y.columns=[0,1,2]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standardized, encoded_y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train.reset_index(inplace=True)\n",
    "y_train.drop(columns=['index'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation(X):\n",
    "    \n",
    "    W = np.random.randn(X.shape[1],3)\n",
    "    b = pd.Series(np.random.randn(3))\n",
    "    return W, b\n",
    "\n",
    "\n",
    "def model(X, W, b):\n",
    "    \n",
    "    Z = X.dot(W) + np.tile(b.values.T, (6610, 1))\n",
    "    A = pd.DataFrame(np.exp(Z))\n",
    "\n",
    "    for k in range(len(A)):\n",
    "        for i in range(3):\n",
    "            A.iloc[k,i] = A.iloc[k,i] / (A.iloc[k,:]).sum(axis=0)\n",
    "    return A\n",
    "\n",
    "def gradients(A, X, y):\n",
    "    \n",
    "    dW = 1 / len(y_train) * np.dot(X.T, A - y)\n",
    "    db = 1 / len(y_train) * np.sum(A - y,axis=0)\n",
    "    return (dW, db)\n",
    "\n",
    "def update(dW, db, W, b, learning_rate):\n",
    "\n",
    "    W = W - learning_rate * dW\n",
    "    b = b - learning_rate * db\n",
    "\n",
    "    return (W, b)\n",
    "\n",
    "def predict(X, W, b):\n",
    "    A = model(X, W, b)\n",
    "    return A >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artificial_neuron(X_train, y_train, learning_rate = 0.1, n_iter = 100):\n",
    "\n",
    "    W, b = initialisation(X_train)\n",
    "\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        \n",
    "        A = model(X_train, W, b)\n",
    "        dW, db = gradients(A, X_train, y_train)\n",
    "        W, b = update(dW, db, W, b, learning_rate)\n",
    "        print(log_loss(y_train, A))\n",
    "    \n",
    "    return (W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = artificial_neuron(X_train, y_train, learning_rate = 0.1, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = X_test.dot(W) + np.tile(b.values.T, (1653, 1))\n",
    "\n",
    "y_pred = []\n",
    "for k in y_proba:\n",
    "    y_pred += [k.argmax()]\n",
    "encoded_y_pred = pd.get_dummies(y_pred).applymap(lambda x: 1 if x else 0)\n",
    "encoded_y_pred.columns=[0,1,2]\n",
    "accuracy_score(encoded_y_pred,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
